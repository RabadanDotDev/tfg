\color{blue} %TODO remove this when revised
\section{Uso de la herramienta}

En esta sección trataremos el proceso de hacer uso de la herramienta para el entrenamiento de modelos. Primero extraeremos las etiquetas de cada dataset para posteriormente ejecutar nuestra herramienta sobre los datos en crudo. Una vez tengamos las características extraídas, haremos una fase de preprocesamiento de los datos donde analizaremos las diferentes propiedades de este, escalando y normalizando los datos donde posible. Con los datos limpiados, realizaremos una selección de características para mantener solo las que se consideren más relevantes. Una vez hecho esto, detallaremos la tarea de \gls{ml} que se realizará y como evaluaremos los diferentes modelos. A continuación, entrenaremos diferentes modelos y valoraremos su efectividad. Finalmente, haremos una comparación de los modelos y decidiremos cuál es el que muestra mejor rendimiento.

\subsection{Extracción etiquetas de los datasets}

Inicialmente, hemos de definir del 'ground truth' que proporcionaremos a la herramienta para realizar el etiquetado durante la ejecución. Es decir, hemos de indicar a la herramienta, a partir de pares de direcciones IP y rangos temporales, qué etiqueta deseamos que asigne para realizar lo indicado en \ref{flowtag}. Para hacer esto, haremos uso del script \texttt{extract\-\_ground\-\_truth\-\_from\-\_datasets.py} disponible en el anexo 1. En este, se lee la información de los archivos CSV ofrecidos en cada dataset presentado en el marco teórico y se transforma para tener el formato esperado. Las columnas que se requieren para la herramienta tener son:

\begin{itemize}
    \item \texttt{low\_ip}: la dirección IP del par de direcciones lexicográficamente menor.
    \item \texttt{high\_ip}: la dirección IP del par de direcciones lexicográficamente mayor.
    \item \texttt{timestamp\_micro\_start}: el tiempo UNIX expresado en microsegundos del primer tiempo donde se ha de asignar la etiqueta seleccionada.
    \item \texttt{timestamp\_micro\_end}:  el tiempo UNIX expresado en microsegundos del último tiempo donde se ha de asignar la etiqueta seleccionada.
    \item \texttt{label}: la etiqueta seleccionada.
\end{itemize}

Inicialmente, para cada dataset se renombran de las etiquetas de cada flujo para que sean consistentes. Adicionalmente, en CIC-DDos2019, se convierten todas las etiquetas de WebDDoS a 'benign' para luego poder descartarlas. Se ha decidido hacer esto debido a que había muchos flujos WebDDoS que solapaban con otros, cuando WebDDoS es una de las clases menos representadas, según vimos en el análisis de cada dataset. Si no las eliminásemos, habría que cambiar suposiciones esenciales realizadas tanto en la herramienta como en el planteamiento del formato de los 'ground truth'. Después de esto, tratamos cada conjunto de datos individualmente para obtener las diferentes columnas que se requieren.

Para el caso de CIC-DDos2019, leemos el par de direcciones IP (' Source IP' y ' Destination IP'), la marca temporal inicial (' Timestamp'), la duración del flujo (' Flow Duration') y la etiqueta (' Label') de los registros. La marca temporal está representada como una fecha, siguiendo el formato 'YYYY-MM-DDTHH:MM:SS.SSSSSS'. Sin embargo, no hay ningún tipo de información de la zona horaria utilizada. Si observamos la primera marca de tiempo de los datos generados del 3 de noviembre, podemos ver que se aparece '2018-11-03T09:18:16.964447'. A su vez, si abrimos la primera traza de red del mismo día con WireShark, podemos ver que el segundo paquete tiene la marca de tiempo '2018-11-03 12:18:16.964447' en la zona horaria UTC+0. Correlacionando estos valores, podemos ver que todas las marcas de tiempo de los CSV proporcionados tienen 3 horas menos que UTC. A partir de esto, convertimos todos los valores de tiempo a tiempo UNIX expresados en microsegundos. Las duraciones de flujo ya están representadas en microsegundos, por lo que las utilizamos para encontrar el tiempo UNIX de la finalización del flujo.

Con BoT-IoT, también leemos el par de direcciones IP ('saddr' y 'daddr') y la marca temporal inicial ('stime'). Sin embargo, en vez de duración, tenemos directamente el tiempo del último paquete ('ltime') y la etiqueta está separada en una categoría y una subcategoría ('category' y 'subcategory'). Para mantener consistencia, juntamos las dos últimas para representar la etiqueta.

Finalmente, en TON-IoT tenemos un caso similar que con CIC-DDos2019. Tenemos el par de direcciones IP  ('src\_ip' y 'dst\_ip'), la marca temporal inicial ('ts'), la duración del flujo ('duration') y la etiqueta ('type') de los registros. Sin embargo, la marca temporal está expresada en tiempo UNIX en segundos, con una parte decimal, y la duración en segundos.

Después de poner el mismo formato numérico y semántico en los tres conjuntos de datos, podemos llegar a tener un número considerable de filas. Para hacerlo más fácilmente tratable, primero modificamos las columnas de las direcciones IP de origen y destino para tener una que sea lexicográficamente menor y otra mayor. Esto lo hacemos, ya que en la herramienta el orden del par de IP no es relevante, pero sí lo es para hacer la reducción. La reducción la hacemos a base de juntar intervalos de tiempo entre pares de IP con la misma etiqueta. Es decir, agrupamos todas las filas que tengan el mismo par de dirección IP de origen y destino, las ordenamos por tiempo y, si tenemos registros consecutivos que repiten etiqueta, las combinamos para tener un intervalo más grande que las agrupe. Una vez hecho esto, descartamos todas las filas que sean equivalentes a 'benign', ya que la herramienta pondrá esta etiqueta de todas formas si no hay un intervalo que corresponda.

Después de la compresión, quedan algunos intervalos solapados con el mismo par de direcciones IP. Se han decidido modificar los tiempos de inicio y final para que, en los casos que estén solapados, los tiempos se modifiquen al "centro" de los dos. Es decir, si tenemos un intervalo en los tiempos $[0, 20]$ y otro $[10, 30]$, pasarían a ser $[0, 15]$ y $[15, 30]$ respectivamente. De la manera que está diseñada la herramienta, esta es la operación que tiene más sentido, ya que permite que los flujos se etiqueten con la etiqueta del intervalo con la que corresponden más.

Finalmente, renombramos las etiquetas para que sigan un formato similar y, por cada conjunto de datos, guardamos los datos resultantes en un CSV. No realizamos ningún tipo de fusión de etiquetas adicional, ya que esto se habrá de realizar en el momento en que hagamos el preprocesamiento de los datos generados. Los archivos obtenidos constan de 18 registros para CIC-DDos2019, 181 para BoT-IoT y 1667 para TON-IoT. Comparado con la cantidad original de registros (70 427 637, 73 370 442 y 22 339 021 respectivamente), es una reducción de información considerable.

\subsection{Ejecución con etiquetado}

Una vez extraídas las etiquetas, ejecutaremos la herramienta packet pincer sobre los datos en crudo. Los pasos realizados los podemos encontrar en el script \texttt{execute\-\_packet\-\_pincer\-\_on\-\_data.sh} disponible en el anexo 1. En este, ejecutamos la herramienta pasando los parámetros correctos al programa.

\begin{table}[H]
    \begin{center}
        \resizebox{\columnwidth}{!}{%
            \begin{tabular}{|c | c c c |} 
                \hline
                & \textbf{CIC-DDoS2019} & \textbf{Bot-IoT} & \textbf{TON-IoT} \\
                \hline
                Paquetes procesados                             & 312 191 170 & 549 787 584 & 213 236 852 \\
                Paquetes válidos                                & 286 835 688 & 549 057 279 & 175 845 321 \\
                Paquetes con errores de formato                 &           0 &           0 &   2 884 447 \\
                Paquetes con errores de formato en reensamblado &   3 662 214 &           0 &           0 \\
                Paquetes sin capa de red                        &      44 646 &      59 978 &  23 406 884 \\
                Paquetes sin capa de transporte                 &      44 295 &          18 &      83 211 \\
                Paquetes con una capa de enlace no soportada    &           0 &           0 &           0 \\
                Paquetes con capa de transporte no soportada    &     206 020 &     670 309 &  11 016 984 \\
                Paquetes IP redundantes en reensamblado         &   7 733 364 &           0 &           1 \\
                Paquetes IP sin reensamblado                    &   5 773 214 &           0 &           4 \\
                \hline
            \end{tabular}
        }
    \end{center}
    \caption{Estadísticas de evaluación de paquetes con trazas de red}
    \label{table:statsevalpacketoffline}
\end{table}

Como podemos ver en la Tabla \ref{table:statsevalpacketoffline}, la mayor parte de los paquetes son procesados correctamente. Un 91.87\% en CIC-DDoS2019, 99,86\% en BoT-IoT y un 82,46\% en TON-IoT. El motivo por el que en este ultimo la cantidad de paquetes válidos es menor, es debido a que había un gran número de paquetes sobre SLL que indicaban que usaban Ethernet, pero el protocolo indicado  era un tipo no estandarizado (\texttt{0x0003}).

\begin{table}[H]
    \begin{center}
        \begin{tabular}{|c | c c c |} 
            \hline
            & \textbf{CIC-DDoS2019} & \textbf{Bot-IoT} & \textbf{TON-IoT} \\
            \hline
            Tiempo total & 7m 36,532s & 8m4.634s & 3m39.632s \\
            Tiempo en espacio de usuario & 6m 5,831s  & 7m33.534s & 3m6.868s \\
            Tiempo en espacio de kernel  & 1m 26,014s & 0m28.862s 0 & 0m31.229s \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Estadísticas de tiempo con trazas de red}
    \label{table:statstimeoffline}
\end{table}

Podemos ver que, a pesar del gran número de datos a procesar, los tiempos de ejecución no son extremadamente altos como se puede ver en la Tabla \ref{table:statstimeoffline}. Las capturas contienen datos repartidos en horas, mientras que se han podido tratar en menos de 10 minutos. De todas maneras, es posible que en otros dispositivos con menores recursos el tiempo de ejecución fuese considerablemente más alto.

\begin{table}[H]
    \begin{center}
        \resizebox{\columnwidth}{!}{%
            \begin{tabular}{|c | c c c |} 
                \hline
                & \textbf{CIC-DDoS2019} & \textbf{Bot-IoT} & \textbf{TON-IoT} \\
                \hline
                Número de archivos &          5                &          1                 &          3               \\
                Flujos totales     & 47 159 584                &  6 076 233                 & 25 638 109               \\
                Bytes totales      & 29 651 536 KiB (\~29 GiB) &  3 927 136 KiB (\~3,8 GiB) & 15 469 692 KiB (\~15 GiB)\\
                \hline
            \end{tabular}
        }
    \end{center}
    \caption{Archivos generados con trazas de red}
    \label{table:generatedfilesoffline}
\end{table}

Finalmente, en la tabla \ref{table:generatedfilesoffline} podemos ver la magnitud de datos generados. En total, contamos con más de 49 GiB de datos, los cuales comprenden casi 79 millones de registros. En el momento de tratar estos datos, tendremos que tener en cuenta que los modelos y pasos a realizar deben ser capaces de operar con esta magnitud de datos con los recursos disponibles.

\subsection{Preprocessamiento datos generados}

por hacer

\subsection{Definición y evaluación de la tarea a realizar}

por hacer

\subsection{Entrenamiento de modelos}

por hacer

\subsection{Comparación de resultados}

por hacer

