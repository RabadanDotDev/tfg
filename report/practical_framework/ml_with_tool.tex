\section{Uso de la herramienta}

En esta sección trataremos el proceso de hacer uso de la herramienta para el entrenamiento de modelos. Primero extraeremos las etiquetas de cada dataset para posteriormente ejecutar nuestra herramienta sobre los datos en crudo. Una vez tengamos las características extraídas, haremos una fase de preprocesamiento de los datos donde analizaremos las diferentes propiedades de este, escalando y normalizando los datos donde posible. Con los datos limpiados, realizaremos una selección de características para mantener solo las que se consideren más relevantes. Una vez hecho esto, detallaremos la tarea de \gls{ml} que se realizará y como evaluaremos los diferentes modelos. A continuación, entrenaremos diferentes modelos y valoraremos su efectividad. Finalmente, haremos una comparación de los modelos y decidiremos cuál es el que muestra mejor rendimiento.

\subsection{Extracción etiquetas de los datasets}

Inicialmente, hemos de definir del 'ground truth' que proporcionaremos a la herramienta para realizar el etiquetado durante la ejecución. Es decir, hemos de indicar a la herramienta, a partir de pares de direcciones IP y rangos temporales, qué etiqueta deseamos que asigne para realizar lo indicado en \ref{flowtag}. Para hacer esto, haremos uso del script \texttt{extract\-\_ground\-\_truth\-\_from\-\_datasets.py} disponible en el anexo 1. En este, se lee la información de los archivos CSV ofrecidos en cada dataset presentado en el marco teórico y se transforma para tener el formato esperado. Las columnas que se requieren para la herramienta tener son:

\begin{itemize}
    \item \texttt{low\_ip}: la dirección IP del par de direcciones lexicográficamente menor
    \item \texttt{high\_ip}: la dirección IP del par de direcciones lexicográficamente mayor
    \item \texttt{timestamp\_micro\_start}: el tiempo UNIX expresado en microsegundos del primer tiempo donde se ha de asignar la etiqueta seleccionada.
    \item \texttt{timestamp\_micro\_end}:  el tiempo UNIX expresado en microsegundos del último tiempo donde se ha de asignar la etiqueta seleccionada.
    \item \texttt{label}: la etiqueta seleccionada
\end{itemize}

Inicialmente, para cada dataset se renombran de las etiquetas de cada flujo para que sean consistentes. Adicionalmente, en CIC-DDos2019, se convierten todas las etiquetas de WebDDoS a 'benign' para luego poder descartarlas. Se ha decidido hacer esto debido a que había muchos flujos WebDDoS que solapaban con otros, cuando WebDDoS es una de las clases menos representadas, según vimos en el análisis de cada dataset. Si no las eliminásemos, habría que cambiar suposiciones esenciales realizadas tanto en la herramienta como en el planteamiento del formato de los 'ground truth'. Después de esto, tratamos cada conjunto de datos individualmente para obtener las diferentes columnas que se requieren.

Para el caso de CIC-DDos2019, leemos el par de direcciones IP (' Source IP' y ' Destination IP'), la marca temporal inicial (' Timestamp'), la duración del flujo (' Flow Duration') y la etiqueta (' Label') de los registros. La marca temporal está representada como una fecha, siguiendo el formato 'YYYY-MM-DDTHH:MM:SS.SSSSSS'. Sin embargo, no hay ningún tipo de información de la zona horaria utilizada. Si observamos la primera marca de tiempo de los datos generados del 3 de noviembre, podemos ver que se aparece '2018-11-03T09:18:16.964447'. A su vez, si abrimos la primera traza de red del mismo día con WireShark, podemos ver que el segundo paquete tiene la marca de tiempo '2018-11-03 12:18:16.964447' en la zona horaria UTC+0. Correlacionando estos valores, podemos ver que todas las marcas de tiempo de los CSV proporcionados tienen 3 horas menos que UTC. A partir de esto, convertimos todos los valores de tiempo a tiempo UNIX expresados en microsegundos. Las duraciones de flujo ya están representadas en microsegundos, por lo que las utilizamos para encontrar el tiempo UNIX de la finalización del flujo.

Con BoT-IoT, también leemos el par de direcciones IP ('saddr' y 'daddr') y la marca temporal inicial ('stime'). Sin embargo, en vez de duración, tenemos directamente el tiempo del último paquete ('ltime') y la etiqueta está separada en una categoría y una subcategoría ('category' y 'subcategory'). Para mantener consistencia, juntamos las dos últimas para representar la etiqueta.

Finalmente, en TON-IoT tenemos un caso similar que con CIC-DDos2019. Tenemos el par de direcciones IP  ('src\_ip' y 'dst\_ip'), la marca temporal inicial ('ts'), la duración del flujo ('duration') y la etiqueta ('type') de los registros. Sin embargo, la marca temporal está expresada en tiempo UNIX en segundos, con una parte decimal, y la duración en segundos.

Después de poner el mismo formato numérico y semántico en los tres conjuntos de datos, podemos llegar a tener un número considerable de filas. Para hacerlo más fácilmente tratable, primero modificamos las columnas de las direcciones IP de origen y destino para tener una que sea lexicográficamente menor y otra mayor. Esto lo hacemos, ya que en la herramienta el orden del par de IP no es relevante, pero sí lo es para hacer la reducción. La reducción la hacemos a base de juntar intervalos de tiempo entre pares de IP con la misma etiqueta. Es decir, agrupamos todas las filas que tengan el mismo par de dirección IP de origen y destino, las ordenamos por tiempo y, si tenemos registros consecutivos que repiten etiqueta, las combinamos para tener un intervalo más grande que las agrupe. Una vez hecho esto, descartamos todas las filas que sean equivalentes a 'benign', ya que la herramienta pondrá esta etiqueta de todas formas si no hay un intervalo que corresponda.

Después de la compresión, quedan algunos intervalos solapados con el mismo par de direcciones IP. Se han decidido modificar los tiempos de inicio y final para que, en los casos que estén solapados, los tiempos se modifiquen al "centro" de los dos. Es decir, si tenemos un intervalo en los tiempos $[0, 20]$ y otro $[10, 30]$, pasarían a ser $[0, 15]$ y $[15, 30]$ respectivamente. De la manera que está diseñada la herramienta, esta es la operación que tiene más sentido, ya que permite que los flujos se etiqueten con la etiqueta del intervalo con la que corresponden más.

Finalmente, renombramos las etiquetas para que sigan un formato similar y, por cada conjunto de datos, guardamos los datos resultantes en un CSV. No realizamos ningún tipo de fusión de etiquetas adicional, ya que esto se habrá de realizar en el momento en que hagamos el preprocesamiento de los datos generados. Los archivos obtenidos constan de 18 registros para CIC-DDos2019, 181 para BoT-IoT y 1667 para TON-IoT. Comparado con la cantidad original de registros (70 427 637, 73 370 442 y 22 339 021 respectivamente), es una reducción de información considerable.

\subsection{Ejecución con etiquetado}

Por hacer

\subsection{Preprocessamiento datos generados}

por hacer

\subsection{Definición y evaluación de la tarea a realizar}

por hacer

\subsection{Entrenamiento de modelos}

por hacer

\subsection{Comparación de resultados}

por hacer

